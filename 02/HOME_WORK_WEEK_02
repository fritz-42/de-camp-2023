
DE camp 2023 homework week 02

- Question 1. Load January 2020 data
  Using the etl_web_to_gcs.py flow that loads taxi data into GCS as a guide,
  create a flow that loads the green taxi CSV dataset for January 2020 into GCS and run it.
  Look at the logs to find out how many rows the dataset has.
  How many rows does that dataset have?

  => change variables in cat etl_web_to_gcs.py
     color = "green"
     year = 2020

  $python etl_web_to_gcs.py
  13:51:13.701 | INFO    | Task run 'write_gcs-1145c921-0' - Uploading from Path('data/green/green_tripdata_2020-01.parquet')
                           to the bucket 'dtc_data_lake_mlops-zoom-camp-2023' path 'data/green/green_tripdata_2020-01.parquet'
  13:51:11.509 | INFO    | Task run 'clean-b9fd7e03-0' - rows: 447770

  => 447770

- Question 2. Scheduling with Cron

  Cron is a common scheduling specification for workflows.
  Using the flow in etl_web_to_gcs.py, create a deployment to run on the first of every month at 5am UTC.
  What’s the cron schedule for that?

  cron schedule format

 * * * * *  command to execute
 ┬ ┬ ┬ ┬ ┬
 │ │ │ │ │
 │ │ │ │ │
 │ │ │ │ └───── day of week (0 - 7) (0 to 6 are Sunday to Saturday, or use names; 7 is Sunday, the same as 0)
 │ │ │ └────────── month (1 - 12)
 │ │ └─────────────── day of month (1 - 31)
 │ └──────────────────── hour (0 - 23)
 └───────────────────────── min (0 - 59)

  => 0 5 1 * *

  $ prefect deployment build ./etl_web_to_gcs_params.py:etl_parent_flow -n "ETL with cron: first every month at 5am" --cron "0 5 1 * *" -a
  Deployment 'etl-parent-flow/ETL with cron: first every month at 5am' successfully created with id 'ff9984d7-1bd7-4b03-bd75-14452349143b'

  web UI: Schedule
          At 05:00 AM on day 1 of the month (UTC)


- Question 3. Loading data to BigQuery

  14:57:14.470 | INFO    | Task run 'extract_from_gcs-968e3b65-0' - Downloading blob named data/yellow/yellow_tripdata_2019-02.parquet from the dtc_data_lake_mlops-zoom-camp-2023 bucket to ../data/data/yellow/yellow_tripdata_2019-02.parquet
  14:57:17.525 | INFO    | Task run 'transform-a7d916b4-0' - read rows: 7019375

  14:57:42.327 | INFO    | Task run 'extract_from_gcs-968e3b65-0' - Downloading blob named data/yellow/yellow_tripdata_2019-03.parquet from the dtc_data_lake_mlops-zoom-camp-2023 bucket to ../data/data/yellow/yellow_tripdata_2019-03.parquet
  14:57:45.589 | INFO    | Task run 'transform-a7d916b4-0' - read rows: 7832545

  => 7019375 + 7832545 = 14851920

  SELECT count(*) FROM `mlops-zoom-camp-2023.de_camp_dataset.rides`;
  14851920


- Question 4. Github Storage Block

  => create GitHub Block on the web UI
    - Name: etl-web-to-gcs-flow
    - Repository: https://github.com/fritz-42/de-camp-2023/
    

  => create deployment using github_deploy.py

    from prefect.deployments import Deployment
    from prefect.filesystems import GitHub
    from etl_web_to_gcs_params import etl_parent_flow

    github_block = GitHub.load("etl-web-to-gcs-flow")

    github_dep = Deployment.build_from_flow(
               flow = etl_parent_flow,
               name = 'github-flow',
               storage = github_block,
               parameters = {"color": "green", "months": [11], "year": 2020}
    )

    if __name__ == '__main__':
       github_dep.apply()

   $ python github_deploy.py
   => start deployment on the UI
   $ prefect agent start -q default

   10:19:48.124 | INFO    | Task run 'clean-2c6af9f6-0' - rows: 88605

   => 88605
   
- Question 5. Email or Slack notifications

  => 514392

- Question 6. Secrets

  from prefect.blocks.system import Secret
  secret_block = Secret.load("de-camp-secret")

  # Access the stored secret
  secret_block.get()

  Value
  => ******** => 8 stars
